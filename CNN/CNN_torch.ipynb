{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f29c41-f12f-4ceb-b8ce-2d3a68b8c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80708c73-210c-4425-9535-c6972ff48217",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory= '/Users/guill/Escritorio/TesisLisboa/archive/DFU'\n",
    "root_directory = os.path.join(dataset_directory, \"Patches\")\n",
    "\n",
    "Abnormal_directory = os.path.join(root_directory, \"Abnormal\")\n",
    "Normal_directory = os.path.join(root_directory, \"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fb4d73-8d98-4d10-bad1-e0da2b285b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "543\n",
      "1055\n",
      "738 317\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Abnormal_images_filepaths = sorted([os.path.join(Abnormal_directory, f) for f in os.listdir(Abnormal_directory)])\n",
    "Normal_images_filepaths = sorted([os.path.join(Normal_directory, f) for f in os.listdir(Normal_directory)])\n",
    "images_filepaths = [*Abnormal_images_filepaths, *Normal_images_filepaths]\n",
    "correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(correct_images_filepaths)\n",
    "\n",
    "total_images = len(correct_images_filepaths)\n",
    "train_split = int(total_images * 0.7)\n",
    "val_split = total_images - train_split\n",
    "\n",
    "train_images_filepaths = correct_images_filepaths[:train_split]\n",
    "val_images_filepaths = correct_images_filepaths[train_split:]\n",
    "\n",
    "print(len(Abnormal_images_filepaths))\n",
    "\n",
    "print(len(Normal_images_filepaths))\n",
    "\n",
    "print(len(correct_images_filepaths))\n",
    "\n",
    "print(len(train_images_filepaths), len(val_images_filepaths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb2432a7-3fab-4498-b6a0-b5ca450030a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef display_image_grid(images_filepaths, predicted_labels=(), cols=5):\\n    rows = len(images_filepaths) // cols\\n    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\\n    for i, image_filepath in enumerate(images_filepaths):\\n        image = cv2.imread(image_filepath)\\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n        true_label = os.path.normpath(image_filepath).split(os.sep)[-2]\\n        predicted_label = predicted_labels[i] if predicted_labels else true_label\\n        color = \"green\" if true_label == predicted_label else \"red\"\\n        ax.ravel()[i].imshow(image)\\n        ax.ravel()[i].set_title(predicted_label, color=color)\\n        ax.ravel()[i].set_axis_off()\\n    plt.tight_layout()\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def display_image_grid(images_filepaths, predicted_labels=(), cols=5):\n",
    "    rows = len(images_filepaths) // cols\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
    "    for i, image_filepath in enumerate(images_filepaths):\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        true_label = os.path.normpath(image_filepath).split(os.sep)[-2]\n",
    "        predicted_label = predicted_labels[i] if predicted_labels else true_label\n",
    "        color = \"green\" if true_label == predicted_label else \"red\"\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_title(predicted_label, color=color)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34bacfca-1636-4af1-96ca-b54c6b7a309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(10):\\n    img_path = train_images_filepaths[i]\\n    img = cv2.imread(img_path)\\n    label = img_path.split('/')[-1].capitalize() # Obtiene la etiqueta según el nombre de archivo\\n    \\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\\n    plt.title(label)  # Muestra el título de la imagen como la etiqueta correspondiente\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(10):\n",
    "    img_path = train_images_filepaths[i]\n",
    "    img = cv2.imread(img_path)\n",
    "    label = img_path.split('/')[-1].capitalize() # Obtiene la etiqueta según el nombre de archivo\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(label)  # Muestra el título de la imagen como la etiqueta correspondiente\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4712549-8369-48aa-89da-41cae098b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NormalVsAbnormalDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"Normal\":\n",
    "            label = 1.0\n",
    "        else:\n",
    "            label = 0.0\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "            \n",
    "        return image, label\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a14ceba-e8df-44e4-b9ed-19dec13b508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#adding Luv and cmyk to the rgb tensor\\nimport numpy as np\\nfrom PIL import Image\\n\\nclass NormalVsAbnormalDataset(Dataset):\\n    def __init__(self, images_filepaths, transform=None):\\n        self.images_filepaths = images_filepaths\\n        self.transform = transform\\n\\n    def __len__(self):\\n        return len(self.images_filepaths)\\n\\n    def __getitem__(self, idx):\\n        image_filepath = self.images_filepaths[idx]\\n        image = cv2.imread(image_filepath)\\n        image_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n        image_cmyk = np.array(Image.fromarray(image).convert(\\'CMYK\\'))\\n        image_cmy = image_cmyk[..., :3]  # Seleccionar solo los canales C, M y Y\\n        image_luv = cv2.cvtColor(image, cv2.COLOR_RGB2Luv)\\n\\n        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"Normal\":\\n            label = 1.0\\n        else:\\n            label = 0.0\\n\\n        if self.transform is not None:\\n            image_RGB = self.transform(image=image_RGB)[\"image\"]\\n            image_luv = self.transform(image=image_luv)[\"image\"]\\n            image_cmy = self.transform(image=image_cmy)[\"image\"]\\n          # Convert numpy arrays to PyTorch tensors\\n        image_RGB = torch.from_numpy(image_RGB.transpose(2, 0, 1))\\n        image_luv = torch.from_numpy(image_luv.transpose(2, 0, 1))\\n        image_cmy = torch.from_numpy(np.array(image_cmy).transpose(2, 0, 1))\\n        #print(image_RGB.shape)\\n        #print(image_luv.shape)\\n        #print(image_cmy.shape)\\n\\n\\n\\n        # Concatenate the three representations of color\\n        image = torch.cat((image_RGB, image_cmy, image_luv), dim=2)\\n        #print(image.shape)\\n\\n        return image, label\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#adding Luv and cmyk to the rgb tensor\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class NormalVsAbnormalDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_cmyk = np.array(Image.fromarray(image).convert('CMYK'))\n",
    "        image_cmy = image_cmyk[..., :3]  # Seleccionar solo los canales C, M y Y\n",
    "        image_luv = cv2.cvtColor(image, cv2.COLOR_RGB2Luv)\n",
    "\n",
    "        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"Normal\":\n",
    "            label = 1.0\n",
    "        else:\n",
    "            label = 0.0\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image_RGB = self.transform(image=image_RGB)[\"image\"]\n",
    "            image_luv = self.transform(image=image_luv)[\"image\"]\n",
    "            image_cmy = self.transform(image=image_cmy)[\"image\"]\n",
    "          # Convert numpy arrays to PyTorch tensors\n",
    "        image_RGB = torch.from_numpy(image_RGB.transpose(2, 0, 1))\n",
    "        image_luv = torch.from_numpy(image_luv.transpose(2, 0, 1))\n",
    "        image_cmy = torch.from_numpy(np.array(image_cmy).transpose(2, 0, 1))\n",
    "        #print(image_RGB.shape)\n",
    "        #print(image_luv.shape)\n",
    "        #print(image_cmy.shape)\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate the three representations of color\n",
    "        image = torch.cat((image_RGB, image_cmy, image_luv), dim=2)\n",
    "        #print(image.shape)\n",
    "\n",
    "        return image, label\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60bf5dd-0bfe-493d-8ef6-5777e7e31d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=160),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=20, p=0.5),#change and try other numbers\n",
    "        A.RandomCrop(height=128, width=128),\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1),brightness_by_max=True, p=0.7),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.5),#meter ruido gausiano\n",
    "        #A.HueSaturationValue (hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, always_apply=False, p=0.5),#Cambiar aleatoriamente el tono, la saturación y el valor de la imagen de entrada\n",
    "        A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=5, always_apply=False, p=0.5),\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(), #solo lo quito si en la funcion de arriba estoy ya creando el tensor\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = NormalVsAbnormalDataset(images_filepaths=train_images_filepaths, transform=train_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5df0cb-ac1b-42ab-a1e7-bd6311f8d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=160),\n",
    "        A.CenterCrop(height=128, width=128),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),  #solo lo quito si en la funcion de arriba estoy ya creando el tensor\n",
    "    ]\n",
    ")\n",
    "val_dataset = NormalVsAbnormalDataset(images_filepaths=val_images_filepaths, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac54adf4-d7df-4391-bf2c-4f5bc5ab4e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#funcion para visualizar las tres versiones de color: RGB LUV y CMYK\\n\\ndef visualize_augmentations(dataset, idx=0, samples=2, cols=1):\\n    dataset = copy.deepcopy(dataset)\\n    dataset.transform = A.Compose([t for t in dataset.transform.transforms if not isinstance(t, (A.Normalize, ToTensorV2))])\\n    rows = samples // cols\\n    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\\n    for i in range(samples):\\n        image, _ = dataset[idx]\\n        image_rgb = image[:3, :, :]\\n        image_luv = image[3:6, :, :]\\n        image_cmy = image[6:, :, :]\\n        image = torch.cat((image_rgb, image_cmy, image_luv), dim=0)\\n        image = image.permute(1, 2, 0).numpy()\\n        ax.ravel()[i].imshow(image)\\n        ax.ravel()[i].set_axis_off()\\n    plt.tight_layout()\\n    plt.show()\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#funcion para visualizar las tres versiones de color: RGB LUV y CMYK\n",
    "\n",
    "def visualize_augmentations(dataset, idx=0, samples=2, cols=1):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    dataset.transform = A.Compose([t for t in dataset.transform.transforms if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    rows = samples // cols\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
    "    for i in range(samples):\n",
    "        image, _ = dataset[idx]\n",
    "        image_rgb = image[:3, :, :]\n",
    "        image_luv = image[3:6, :, :]\n",
    "        image_cmy = image[6:, :, :]\n",
    "        image = torch.cat((image_rgb, image_cmy, image_luv), dim=0)\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e763ab1b-1d55-47b6-b289-6af6c27e36e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef visualize_augmentations(dataset, idx=0, samples=15, cols=5):\\n    dataset = copy.deepcopy(dataset)\\n    dataset.transform = A.Compose([t for t in dataset.transform.transforms if not isinstance(t, (A.Normalize, ToTensorV2))])\\n    rows = samples // cols\\n    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\\n    for i in range(samples):\\n        image, _ = dataset[idx]\\n        ax.ravel()[i].imshow(image)\\n        ax.ravel()[i].set_axis_off()\\n    plt.tight_layout()\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def visualize_augmentations(dataset, idx=0, samples=15, cols=5):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    dataset.transform = A.Compose([t for t in dataset.transform.transforms if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    rows = samples // cols\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
    "    for i in range(samples):\n",
    "        image, _ = dataset[idx]\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66981c3e-988f-4eb6-9c7f-a1aafab37bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrandom.seed(46)\\nvisualize_augmentations(train_dataset)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "random.seed(46)\n",
    "visualize_augmentations(train_dataset)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dc1736f-8f82-4538-9f18-91513e205385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(output, target):\n",
    "    output = torch.sigmoid(output) >= 0.5\n",
    "    target = target == 1.0\n",
    "    return torch.true_divide((target == output).sum(dim=0), output.size(0)).item()\n",
    "\n",
    "\n",
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += float(val)\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "    def get_avg(self, metric_name):\n",
    "        values = self.metrics[metric_name].values()\n",
    "        avg = sum([value for value in values if isinstance(value, (float, int))]) / len(values)\n",
    "        return avg\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7eef26e-ae33-42d3-ad6f-774334505e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    #otros modelos:\"resnet18\"\"alexnet\"\"vgg16\"\"densenet121\" ResNet18, ResNet34, ResNet50, ResNet101, ResNet152\n",
    "#VGG11, VGG13, VGG16, VGG19\n",
    "#DenseNet121, DenseNet161, DenseNet169, DenseNet201\n",
    "#InceptionV3, InceptionResNetV2\n",
    "#MobileNetV2, MobileNetV3\n",
    "#EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
    "    \"model\": \"efficientNetB2\",\n",
    "    \"device\": \"cpu\",  # usar 'cuda' para usar la GPU\n",
    "    \"lr\": 0.001, #cambiar a 0.01\n",
    "    \"batch_size\": 64,#cambiar a 32\n",
    "    \"num_workers\": 0,\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "#params[\"model\"] = MyModel().to(params[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef939793-a38a-4c2a-b6e4-0060bbe9ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esto funciona siempre\n",
    "#model = getattr(models, params[\"model\"])(weights=None, num_classes=1,)\n",
    "#model = model.to(params[\"device\"])\n",
    "#criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf23e13-3140-411a-be93-b9b9aff80802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#ResNet101\\n\\nfrom torchvision.models import resnet101, ResNet101_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet101_Weights.DEFAULT)  # Cargar ResNet101 con pesos pre-entrenados\\n\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\nmodel = model.to(params[\"device\"])\\n\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\noptimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "#ResNet101\n",
    "\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet101_Weights.DEFAULT)  # Cargar ResNet101 con pesos pre-entrenados\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "model = model.to(params[\"device\"])\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8041245f-a7c4-4a66-83a6-16da3dda65fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#solo congelo la ultimas 2 capas\\n\\nimport torch.nn as nn\\nfrom torchvision.models import resnet101, ResNet101_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet101_Weights.DEFAULT)  # Cargar ResNet101 con pesos pre-entrenados\\n\\n# Congelar todas las capas excepto las últimas\\nfor name, param in model.named_parameters():\\n    if not any(layer in name for layer in [\\'layer4\\', \\'fc\\']):\\n        param.requires_grad = False\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "#solo congelo la ultimas 2 capas\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet101_Weights.DEFAULT)  # Cargar ResNet101 con pesos pre-entrenados\n",
    "\n",
    "# Congelar todas las capas excepto las últimas\n",
    "for name, param in model.named_parameters():\n",
    "    if not any(layer in name for layer in ['layer4', 'fc']):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f84bb0df-b0c1-428d-8643-71b62b8bb7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#solo congelo la ultimas 5 capas\\n\\nimport torch.nn as nn\\nfrom torchvision.models import resnet101, ResNet101_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet101_Weights.DEFAULT)  # Cargar ResNet101 con pesos pre-entrenados\\n\\n# Congelar todas las capas excepto las últimas\\nfor name, param in model.named_parameters():\\n    if not any(layer in name for layer in [\\'layer4\\', \\'fc\\', \\'layer3.22\\', \\'layer3.21\\', \\'layer3.20\\']):\\n        param.requires_grad = False\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "#solo congelo la ultimas 5 capas\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet101_Weights.DEFAULT)  # Cargar ResNet101 con pesos pre-entrenados\n",
    "\n",
    "# Congelar todas las capas excepto las últimas\n",
    "for name, param in model.named_parameters():\n",
    "    if not any(layer in name for layer in ['layer4', 'fc', 'layer3.22', 'layer3.21', 'layer3.20']):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03c7f993-9550-44be-9088-74a65010dc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#solo congelo la ultimas 7 capas\\n\\nimport torch.nn as nn\\nfrom torchvision.models import resnet101, ResNet101_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet101_Weights.DEFAULT)  # Cargar ResNet101 con pesos pre-entrenados\\n\\n# Congelar todas las capas excepto las últimas\\nfor name, param in model.named_parameters():\\n    if not any(layer in name for layer in [\\'layer4\\', \\'fc\\', \\'layer3.22\\', \\'layer3.21\\', \\'layer3.20\\',\\'layer3.19\\', \\'layer3.18\\', \\'layer3.17\\']):\\n        param.requires_grad = False\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "#solo congelo la ultimas 7 capas\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet101_Weights.DEFAULT)  # Cargar ResNet101 con pesos pre-entrenados\n",
    "\n",
    "# Congelar todas las capas excepto las últimas\n",
    "for name, param in model.named_parameters():\n",
    "    if not any(layer in name for layer in ['layer4', 'fc', 'layer3.22', 'layer3.21', 'layer3.20','layer3.19', 'layer3.18', 'layer3.17']):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c7b0fd9-ffe1-41b0-a670-42989765b83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#resnet50 \\n\\n\\nfrom torchvision.models import resnet50, ResNet50_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\n\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\nmodel = model.to(params[\"device\"])\\n\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\noptimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#resnet50 \n",
    "\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "model = model.to(params[\"device\"])\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8bd1649-0398-4809-8c09-994e14836a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#solo congelo la ultima capa\\n\\nimport torch.nn as nn\\nfrom torchvision.models import resnet50, ResNet50_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\n# Congelar todas las capas excepto la última capa lineal\\nfor name, param in model.named_parameters():\\n    if \"fc\" not in name:\\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#solo congelo la ultima capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "# Congelar todas las capas excepto la última capa lineal\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ada966b8-2ac1-4744-af1d-66846b9a22b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelar todas las capas menos las 5 ultimas\\nimport torch.nn as nn\\nfrom torchvision.models import resnet50, ResNet50_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\n\\n# Congelar todas las capas excepto las últimas\\nfor name, param in model.named_parameters():\\n    if not any(layer in name for layer in [\\'layer4\\', \\'fc\\']):\\n        param.requires_grad = False\\n\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelar todas las capas menos las 5 ultimas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "\n",
    "# Congelar todas las capas excepto las últimas\n",
    "for name, param in model.named_parameters():\n",
    "    if not any(layer in name for layer in ['layer4', 'fc']):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "805d75f4-3e85-4bce-9822-a88b58ee8c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelar todas las capas menos las 7 ultimas\\nimport torch.nn as nn\\nfrom torchvision.models import resnet50, ResNet50_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\n\\n# Congelar todas las capas excepto las últimas\\nfor name, param in model.named_parameters():\\n    if not any(layer in name for layer in [\\'layer4\\', \\'fc\\', \\'layer3.5\\']):\\n        param.requires_grad = False\\n\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelar todas las capas menos las 7 ultimas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "\n",
    "# Congelar todas las capas excepto las últimas\n",
    "for name, param in model.named_parameters():\n",
    "    if not any(layer in name for layer in ['layer4', 'fc', 'layer3.5']):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6dd3bf6-769a-4d73-b909-02510c2f9770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelar todas las capas menos las 8 ultimas\\nimport torch.nn as nn\\nfrom torchvision.models import resnet50, ResNet50_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\n\\n# Congelar todas las capas excepto las últimas\\nfor name, param in model.named_parameters():\\n    if not any(layer in name for layer in [\\'layer4\\', \\'fc\\', \\'layer3.5\\',\\'layer3.4\\']):\\n        param.requires_grad = False\\n\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelar todas las capas menos las 8 ultimas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "\n",
    "# Congelar todas las capas excepto las últimas\n",
    "for name, param in model.named_parameters():\n",
    "    if not any(layer in name for layer in ['layer4', 'fc', 'layer3.5','layer3.4']):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e804b532-d118-400e-abf0-111243c92418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelar todas las capas menos las 2 ultimas\\nimport torch.nn as nn\\nfrom torchvision.models import resnet50, ResNet50_Weights\\n\\nmodel = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\n\\n# Congelar todas las capas excepto las últimas\\nfor name, param in model.named_parameters():\\n    if not any(layer in name for layer in [\\'layer4.1\\', \\'fc\\']):\\n        param.requires_grad = False\\n\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.fc.in_features\\nmodel.fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelar todas las capas menos las 2 ultimas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = getattr(models, params[\"model\"])(weights=ResNet50_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "\n",
    "# Congelar todas las capas excepto las últimas\n",
    "for name, param in model.named_parameters():\n",
    "    if not any(layer in name for layer in ['layer4.1', 'fc']):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3861e828-ae9b-4c15-834e-a2629b557f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#densenet121\\n\\nfrom torchvision.models import densenet121, DenseNet121_Weights\\nmodel = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\nnum_ftrs = model.classifier.in_features\\nmodel.classifier = nn.Linear(num_ftrs, 1)\\nmodel = model.to(params[\"device\"])\\n\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\noptimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#densenet121\n",
    "\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "model = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)\n",
    "model = model.to(params[\"device\"])\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14b77c2b-b4e8-4b87-8b06-4afc0314ed36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Densenet121\\n#congelo 3 capas\\nimport torch.nn as nn\\nfrom torchvision.models import densenet121, DenseNet121_Weights\\n\\n# Cargar la red DenseNet121 pre-entrenada\\nmodel = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if \"denseblock4\" not in name and \"norm5\" not in name:\\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.classifier.in_features\\nmodel.classifier = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Densenet121\n",
    "#congelo 3 capas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# Cargar la red DenseNet121 pre-entrenada\n",
    "model = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if \"denseblock4\" not in name and \"norm5\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "323ea86a-378b-4929-b3aa-96868bac6928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Densenet121\\n#congelo 2 capas, de la denseblock4.denselayer16 hasta la 13\\nimport torch.nn as nn\\nfrom torchvision.models import densenet121, DenseNet121_Weights\\n\\n# Cargar la red DenseNet121 pre-entrenada\\nmodel = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if \"denseblock4.denselayer16\" not in name and \"norm5\" not in name and \"denseblock4.denselayer15\" not in name and \"denseblock4.denselayer14\" not in name and \"denseblock4.denselayer13\" not in name:\\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.classifier.in_features\\nmodel.classifier = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Densenet121\n",
    "#congelo 2 capas, de la denseblock4.denselayer16 hasta la 13\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# Cargar la red DenseNet121 pre-entrenada\n",
    "model = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if \"denseblock4.denselayer16\" not in name and \"norm5\" not in name and \"denseblock4.denselayer15\" not in name and \"denseblock4.denselayer14\" not in name and \"denseblock4.denselayer13\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5e70975-7923-4dac-bac1-f25213f79ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelo todas las capas menos las ultimas 4 capas\\nimport torch.nn as nn\\nfrom torchvision.models import densenet121, DenseNet121_Weights\\n\\n# Cargar la red DenseNet121 pre-entrenada\\nmodel = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if \"transition3\" not in name and \"denseblock4\" not in name and \"norm5\" not in name:\\n        param.requires_grad = False\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.classifier.in_features\\nmodel.classifier = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelo todas las capas menos las ultimas 4 capas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# Cargar la red DenseNet121 pre-entrenada\n",
    "model = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if \"transition3\" not in name and \"denseblock4\" not in name and \"norm5\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "268cd446-8eb4-4e8b-99bb-1e39dc9cc6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelo todas las capas menos las ultimas 5 capas\\nimport torch.nn as nn\\nfrom torchvision.models import densenet121, DenseNet121_Weights\\n\\n# Cargar la red DenseNet121 pre-entrenada\\nmodel = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'denseblock4\\') and not name.startswith(\\'transition3\\') and not name.startswith(\\'norm5\\') and not name.startswith(\\'denseblock3\\'):\\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.classifier.in_features\\nmodel.classifier = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelo todas las capas menos las ultimas 5 capas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# Cargar la red DenseNet121 pre-entrenada\n",
    "model = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('denseblock4') and not name.startswith('transition3') and not name.startswith('norm5') and not name.startswith('denseblock3'):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03ea46f0-a5a6-46cf-a49a-9865dc8287ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelo todas las capas menos las ultimas 6 capas\\nimport torch.nn as nn\\nfrom torchvision.models import densenet121, DenseNet121_Weights\\n\\n# Cargar la red DenseNet121 pre-entrenada\\nmodel = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'denseblock4\\') and not name.startswith(\\'transition3\\') and not name.startswith(\\'norm5\\') and not name.startswith(\\'denseblock3\\') and not name.startswith(\\'transition2\\'):\\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.classifier.in_features\\nmodel.classifier = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelo todas las capas menos las ultimas 6 capas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# Cargar la red DenseNet121 pre-entrenada\n",
    "model = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('denseblock4') and not name.startswith('transition3') and not name.startswith('norm5') and not name.startswith('denseblock3') and not name.startswith('transition2'):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51a78c30-ecce-4b80-b9af-36a49e142413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelo todas las capas menos las ultimas 7 capas\\nimport torch.nn as nn\\nfrom torchvision.models import densenet121, DenseNet121_Weights\\n\\n# Cargar la red DenseNet121 pre-entrenada\\nmodel = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'denseblock4\\') and not name.startswith(\\'transition3\\') and not name.startswith(\\'norm5\\') and not name.startswith(\\'denseblock3\\') and not name.startswith(\\'transition2\\') and not name.startswith(\\'denseblock2\\'):\\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.classifier.in_features\\nmodel.classifier = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelo todas las capas menos las ultimas 7 capas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# Cargar la red DenseNet121 pre-entrenada\n",
    "model = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('denseblock4') and not name.startswith('transition3') and not name.startswith('norm5') and not name.startswith('denseblock3') and not name.startswith('transition2') and not name.startswith('denseblock2'):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30cbd657-20d4-4e3f-9998-a3986c38f435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#congelo todas las capas menos las ultimas 8 capas\\nimport torch.nn as nn\\nfrom torchvision.models import densenet121, DenseNet121_Weights\\n\\n# Cargar la red DenseNet121 pre-entrenada\\nmodel = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\\n\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'denseblock4\\') and not name.startswith(\\'transition3\\') and not name.startswith(\\'norm5\\') and not name.startswith(\\'denseblock3\\') and not name.startswith(\\'transition2\\') and not name.startswith(\\'denseblock2\\') and not name.startswith(\\'transition1\\'):\\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model.classifier.in_features\\nmodel.classifier = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#congelo todas las capas menos las ultimas 8 capas\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# Cargar la red DenseNet121 pre-entrenada\n",
    "model = getattr(models, params[\"model\"])(weights=DenseNet121_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('denseblock4') and not name.startswith('transition3') and not name.startswith('norm5') and not name.startswith('denseblock3') and not name.startswith('transition2') and not name.startswith('denseblock2') and not name.startswith('transition1'):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49063c5b-3703-4d4a-adf6-3b9763506aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importas la el modelo y los pesos que necesites\n",
    "#recortar alguna capa\n",
    "\n",
    "\n",
    "\n",
    "#from torchvision.models import vgg16\n",
    "#model = vgg16(pretrained=False)\n",
    "#num_ftrs = model.classifier[6].in_features\n",
    "#model.classifier[6] = nn.Linear(num_ftrs, 1)\n",
    "#model = model.to(params[\"device\"])\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39744b73-6001-4feb-aa86-fe1145919e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.models import alexnet, AlexNet_Weights\n",
    "#recortar alguna capa\n",
    "#model = getattr(models, params[\"model\"])(weights=AlexNet_Weights.DEFAULT)#para usar los pesos pre-entrenados de la red\n",
    "#num_ftrs = model.classifier[6].in_features\n",
    "#model.classifier[6] = nn.Linear(num_ftrs, 1) # reemplazar la última capa completamente conectada por una con una salida\n",
    "\n",
    "#model = model.to(params[\"device\"])\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dce360a-53ed-4bb2-95ba-ef2bedcc2232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 1 capa\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n#congelo\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\'): \\n        param.requires_grad = False\\n\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 1 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "#congelo\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92bae33e-aacc-4f95-ae75-17e2b61c772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 3 capa\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\') and not name.startswith(\\'_blocks.21\\') and not name.startswith(\\'_blocks.20\\'): \\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 3 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9c283ec-e3f3-4800-8468-0dd728fbeb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 4 capa\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\') and not name.startswith(\\'_blocks.21\\') and not name.startswith(\\'_blocks.20\\') and not name.startswith(\\'_blocks.19\\'): \\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 4 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20') and not name.startswith('_blocks.19'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e33c7f-dba1-4d8e-82bf-2b431ce626dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 5 capa\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\') and not name.startswith(\\'_blocks.21\\') and not name.startswith(\\'_blocks.20\\') and not name.startswith(\\'_blocks.19\\') and not name.startswith(\\'_blocks.18\\'): \\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 5 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20') and not name.startswith('_blocks.19') and not name.startswith('_blocks.18'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1e5240c-a965-413c-8a20-c3577b5f2a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 6 capa\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\') and not name.startswith(\\'_blocks.21\\') and not name.startswith(\\'_blocks.20\\') and not name.startswith(\\'_blocks.19\\') and not name.startswith(\\'_blocks.18\\') and not name.startswith(\\'_blocks.17\\'): \\n        param.requires_grad = False\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 6 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20') and not name.startswith('_blocks.19') and not name.startswith('_blocks.18') and not name.startswith('_blocks.17'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a46995a-65bd-4d08-a49e-210e7c89b1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 7 capa\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\') and not name.startswith(\\'_blocks.21\\') and not name.startswith(\\'_blocks.20\\') and not name.startswith(\\'_blocks.19\\') and not name.startswith(\\'_blocks.18\\') and not name.startswith(\\'_blocks.17\\') and not name.startswith(\\'_blocks.16\\'): \\n        param.requires_grad = False\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 7 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20') and not name.startswith('_blocks.19') and not name.startswith('_blocks.18') and not name.startswith('_blocks.17') and not name.startswith('_blocks.16'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f05c4c6c-c050-473d-8c17-5617ffaea41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 8 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20') and not name.startswith('_blocks.19') and not name.startswith('_blocks.18') and not name.startswith('_blocks.17') and not name.startswith('_blocks.16') and not name.startswith('_blocks.15'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79f8f4bc-29f1-4034-a8e2-515266642800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 8 capa tuneadas\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\') and not name.startswith(\\'_blocks.21\\') and not name.startswith(\\'_blocks.20\\') and not name.startswith(\\'_blocks.19\\') and not name.startswith(\\'_blocks.18\\') and not name.startswith(\\'_blocks.17\\') and not name.startswith(\\'_blocks.16\\') and not name.startswith(\\'_blocks.15._bn0\\') and not name.startswith(\\'_blocks.15._bn1\\'): \\n        param.requires_grad = False\\n\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 8 capa tuneadas\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20') and not name.startswith('_blocks.19') and not name.startswith('_blocks.18') and not name.startswith('_blocks.17') and not name.startswith('_blocks.16') and not name.startswith('_blocks.15._bn0') and not name.startswith('_blocks.15._bn1'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a5ba555-d454-436d-95ed-67b64c0fd621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 9 capa\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\') and not name.startswith(\\'_blocks.21\\') and not name.startswith(\\'_blocks.20\\') and not name.startswith(\\'_blocks.19\\') and not name.startswith(\\'_blocks.18\\') and not name.startswith(\\'_blocks.17\\') and not name.startswith(\\'_blocks.16\\') and not name.startswith(\\'_blocks.15\\') and not name.startswith(\\'_blocks.14\\'): \\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 9 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20') and not name.startswith('_blocks.19') and not name.startswith('_blocks.18') and not name.startswith('_blocks.17') and not name.startswith('_blocks.16') and not name.startswith('_blocks.15') and not name.startswith('_blocks.14'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af82c057-f625-456b-b021-3fdd8e0e5a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#EfficientNetB2\\n#congelo las ultimas 10 capa\\n\\nimport torch.nn as nn\\nfrom efficientnet_pytorch import EfficientNet\\n\\n# Cargar la red EfficientNet pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\n\\n\\n# Congelar las primeras capas\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_blocks.22\\') and not name.startswith(\\'_blocks.21\\') and not name.startswith(\\'_blocks.20\\') and not name.startswith(\\'_blocks.19\\') and not name.startswith(\\'_blocks.18\\') and not name.startswith(\\'_blocks.17\\') and not name.startswith(\\'_blocks.16\\') and not name.startswith(\\'_blocks.15\\') and not name.startswith(\\'_blocks.14\\') and not name.startswith(\\'_blocks.13\\'): \\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#EfficientNetB2\n",
    "#congelo las ultimas 10 capa\n",
    "\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Cargar la red EfficientNet pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "\n",
    "\n",
    "# Congelar las primeras capas\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_conv_head.') and not name.startswith('_fc.') and not name.startswith('_bn1.') and not name.startswith('_blocks.22') and not name.startswith('_blocks.21') and not name.startswith('_blocks.20') and not name.startswith('_blocks.19') and not name.startswith('_blocks.18') and not name.startswith('_blocks.17') and not name.startswith('_blocks.16') and not name.startswith('_blocks.15') and not name.startswith('_blocks.14') and not name.startswith('_blocks.13'): \n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a8faeab-901b-4a47-9d31-b0408fe3c050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom efficientnet_pytorch import EfficientNet\\n\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b2\\')\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\nmodel = model.to(params[\"device\"])\\n\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\noptimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "model = model.to(params[\"device\"])\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e59b1c6f-74c5-4669-a627-8cba76ffe99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom efficientnet_pytorch import EfficientNet\\n\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b3\\')\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\nmodel = model.to(params[\"device\"])\\n\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\noptimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\\n\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "model = model.to(params[\"device\"])\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44e34d37-174d-43d6-8ae5-abb5f863a732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#efficientNetB3\\n#congelo todas menos las ultimas 2 capa\\nfrom efficientnet_pytorch import EfficientNet\\nimport torch.nn as nn\\n\\n# Cargar la red EfficientNet-B3 pre-entrenada\\nmodel = EfficientNet.from_pretrained(\\'efficientnet-b3\\')\\n\\n#congelo\\nfor name, param in model.named_parameters():\\n    if not name.startswith(\\'_bn1.\\') and not name.startswith(\\'_fc.\\') and not name.startswith(\\'_conv_head.\\') and not name.startswith(\\'_blocks.25\\') and not name.startswith(\\'_blocks.24\\'):\\n        param.requires_grad = False\\n\\n# Reemplazar el clasificador lineal con uno personalizado\\nnum_ftrs = model._fc.in_features\\nmodel._fc = nn.Linear(num_ftrs, 1)\\n\\n# Mover el modelo y el criterio al dispositivo especificado\\nmodel = model.to(params[\"device\"])\\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\\n\\n# Definir el optimizador y ajustar solo los parámetros que no están congelados\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "#efficientNetB3\n",
    "#congelo todas menos las ultimas 2 capa\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch.nn as nn\n",
    "\n",
    "# Cargar la red EfficientNet-B3 pre-entrenada\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "\n",
    "#congelo\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith('_bn1.') and not name.startswith('_fc.') and not name.startswith('_conv_head.') and not name.startswith('_blocks.25') and not name.startswith('_blocks.24'):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Reemplazar el clasificador lineal con uno personalizado\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Mover el modelo y el criterio al dispositivo especificado\n",
    "model = model.to(params[\"device\"])\n",
    "criterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\n",
    "\n",
    "# Definir el optimizador y ajustar solo los parámetros que no están congelados\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params[\"lr\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9a37c36-bcdc-4b8b-b8d4-eb378467c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=params[\"batch_size\"], shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bda0bc6d-0a62-43f9-a2b5-3d72ac753bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef train(train_loader, model, criterion, optimizer, epoch, params):\\n    metric_monitor = MetricMonitor()\\n    model.train()\\n    stream = tqdm(train_loader)\\n    for i, (images, target) in enumerate(stream, start=1):\\n        images = images.to(params[\"device\"], non_blocking=True)\\n        target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\\n        \\n        output = model(images)\\n        loss = criterion(output, target)\\n        accuracy = calculate_accuracy(output, target)\\n        metric_monitor.update(\"Loss\", loss.item())\\n        metric_monitor.update(\"Accuracy\", accuracy)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n        stream.set_description(\\n            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\\n        )\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def train(train_loader, model, criterion, optimizer, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    stream = tqdm(train_loader)\n",
    "    for i, (images, target) in enumerate(stream, start=1):\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        accuracy = calculate_accuracy(output, target)\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Accuracy\", accuracy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "        )\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f0e942d-12a6-40df-9b57-3b00a23651ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef validate(val_loader, model, criterion, epoch, params):\\n    metric_monitor = MetricMonitor()\\n    model.eval()\\n    stream = tqdm(val_loader)\\n    with torch.no_grad():\\n        for i, (images, target) in enumerate(stream, start=1):\\n            images = images.to(params[\"device\"], non_blocking=True)\\n            target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\\n            \\n            output = model(images)\\n            loss = criterion(output, target)\\n            accuracy = calculate_accuracy(output, target)\\n\\n            metric_monitor.update(\"Loss\", loss.item())\\n            metric_monitor.update(\"Accuracy\", accuracy)\\n            stream.set_description(\\n                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\\n            )\\n    return metric_monitor.get_avg(\"Loss\")\\n    \\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(stream, start=1):\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\n",
    "            \n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            accuracy = calculate_accuracy(output, target)\n",
    "\n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"Accuracy\", accuracy)\n",
    "            stream.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "            )\n",
    "    return metric_monitor.get_avg(\"Loss\")\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d55ebb05-b8fc-43da-a176-ccc3b016a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_spatial_attention(images, model):\n",
    "    in_channels = model._blocks[1]._depthwise_conv.out_channels\n",
    "\n",
    "    spatial_attention = SpatialAttention(in_channels=3)\n",
    "\n",
    "\n",
    "    \n",
    "    images_with_attention, attention = spatial_attention(images)  # Aplicar el Spatial Attention a las imágenes\n",
    "    output = model(images_with_attention)  # Pasar las imágenes con atención por el modelo\n",
    "    \n",
    "    return output, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8c33c27-d19d-4bf9-b7d1-9c5fd506e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Calcular los pesos de atención\n",
    "        weights = self.conv(x)\n",
    "        weights = self.sigmoid(weights)\n",
    "        \n",
    "        # Aplicar los pesos de atención a la entrada\n",
    "        x = x * weights\n",
    "        \n",
    "        return x, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9aaa8e13-58c3-4c41-8e75-8713be009e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    stream = tqdm(train_loader)\n",
    "    \n",
    "    for i, (images, target) in enumerate(stream, start=1):\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\n",
    "        \n",
    "        output, attention = apply_spatial_attention(images, model)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        accuracy = calculate_accuracy(output, target)\n",
    "        \n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Accuracy\", accuracy)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "        )\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(stream, start=1):\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\n",
    "            \n",
    "            output, attention = apply_spatial_attention(images, model)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            accuracy = calculate_accuracy(output, target)\n",
    "\n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"Accuracy\", accuracy)\n",
    "            \n",
    "            stream.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "            )\n",
    "    \n",
    "    return metric_monitor.get_avg(\"Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d2f7aed-3185-4329-a6b7-17fe5488ef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train. Loss: 0.278 | Accuracy: 0.897: 100%|██████████████████████████████████| 12/12 [02:48<00:00, 14.06s/it]\n",
      "Epoch: 1. Validation. Loss: 0.097 | Accuracy: 0.965: 100%|███████████████████████████████| 5/5 [00:25<00:00,  5.13s/it]\n",
      "Epoch: 2. Train. Loss: 0.076 | Accuracy: 0.975: 100%|██████████████████████████████████| 12/12 [02:48<00:00, 14.08s/it]\n",
      "Epoch: 2. Validation. Loss: 0.222 | Accuracy: 0.949: 100%|███████████████████████████████| 5/5 [00:25<00:00,  5.08s/it]\n",
      "Epoch: 3. Train. Loss: 0.084 | Accuracy: 0.973: 100%|██████████████████████████████████| 12/12 [02:49<00:00, 14.10s/it]\n",
      "Epoch: 3. Validation. Loss: 0.075 | Accuracy: 0.981: 100%|███████████████████████████████| 5/5 [00:25<00:00,  5.19s/it]\n",
      "Epoch: 4. Train. Loss: 0.066 | Accuracy: 0.979: 100%|██████████████████████████████████| 12/12 [02:51<00:00, 14.27s/it]\n",
      "Epoch: 4. Validation. Loss: 0.094 | Accuracy: 0.988: 100%|███████████████████████████████| 5/5 [00:27<00:00,  5.46s/it]\n",
      "Epoch: 5. Train. Loss: 0.073 | Accuracy: 0.977: 100%|██████████████████████████████████| 12/12 [03:01<00:00, 15.09s/it]\n",
      "Epoch: 5. Validation. Loss: 0.200 | Accuracy: 0.975: 100%|███████████████████████████████| 5/5 [00:27<00:00,  5.46s/it]\n",
      "Epoch: 6. Train. Loss: 0.038 | Accuracy: 0.994:  42%|██████████████▌                    | 5/12 [01:21<01:53, 16.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# inicializa el mejor modelo como vacío\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate(val_loader, model, criterion, epoch, params)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_loss:\n",
      "Cell \u001b[1;32mIn[54], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, epoch, params)\u001b[0m\n\u001b[0;32m      7\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m], non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m], non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m output, attention \u001b[38;5;241m=\u001b[39m \u001b[43mapply_spatial_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     13\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m calculate_accuracy(output, target)\n",
      "Cell \u001b[1;32mIn[52], line 9\u001b[0m, in \u001b[0;36mapply_spatial_attention\u001b[1;34m(images, model)\u001b[0m\n\u001b[0;32m      4\u001b[0m spatial_attention \u001b[38;5;241m=\u001b[39m SpatialAttention(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      8\u001b[0m images_with_attention, attention \u001b[38;5;241m=\u001b[39m spatial_attention(images)  \u001b[38;5;66;03m# Aplicar el Spatial Attention a las imágenes\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_with_attention\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pasar las imágenes con atención por el modelo\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, attention\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\efficientnet_pytorch\\model.py:314\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m\"\"\"EfficientNet's forward function.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m   Calls extract_features to extract features, applies final linear layer, and returns logits.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m    Output of this model after processing.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Convolution layers\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# Pooling and final linear layer\u001b[39;00m\n\u001b[0;32m    316\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_avg_pooling(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\efficientnet_pytorch\\model.py:296\u001b[0m, in \u001b[0;36mEfficientNet.extract_features\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_connect_rate:\n\u001b[0;32m    295\u001b[0m         drop_connect_rate \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(idx) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocks)  \u001b[38;5;66;03m# scale drop connect_rate\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_connect_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_connect_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# Head\u001b[39;00m\n\u001b[0;32m    299\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swish(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_head(x)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\efficientnet_pytorch\\model.py:109\u001b[0m, in \u001b[0;36mMBConvBlock.forward\u001b[1;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[0;32m    106\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn0(x)\n\u001b[0;32m    107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swish(x)\n\u001b[1;32m--> 109\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depthwise_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn1(x)\n\u001b[0;32m    111\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swish(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\efficientnet_pytorch\\utils.py:274\u001b[0m, in \u001b[0;36mConv2dStaticSamePadding.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 274\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatic_padding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\padding.py:25\u001b[0m, in \u001b[0;36m_ConstantPadNd.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# inicializa listas para guardar la pérdida y la precisión durante el entrenamiento\n",
    "best_loss = float(\"inf\")  # inicializa el mejor valor de pérdida a infinito\n",
    "best_model_path = None  # inicializa el mejor modelo como vacío\n",
    "\n",
    "for epoch in range(1, params[\"epochs\"] + 1):\n",
    "    train(train_loader, model, criterion, optimizer, epoch, params)\n",
    "    val_loss = validate(val_loader, model, criterion, epoch, params)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_path = \"best_model_EfficientNetB2_spatialattention.pth\"\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        \n",
    "print(\"Best model saved at\", best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f289ed-8c96-41a7-8b27-b42097893e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the data\n",
    "epochs = range(1, 11)\n",
    "train_losses = [0.238, 0.084, 0.082, 0.034, 0.074, 0.036, 0.042, 0.014, 0.086, 0.055]\n",
    "val_losses = [0.146, 0.189, 0.291, 0.050, 0.063, 0.044, 0.060, 0.036, 0.000, 0.006]\n",
    "train_accs = [0.899, 0.980, 0.977, 0.991, 0.977, 0.990, 0.993, 0.996, 0.975, 0.978]\n",
    "val_accs = [0.971, 0.978, 0.968, 0.990, 0.994, 0.994, 0.994, 0.990, 1.000, 0.997]\n",
    "\n",
    "#train_losses \n",
    "#val_losses \n",
    "#train_accs \n",
    "#val_accs \n",
    "\n",
    "\n",
    "\n",
    "# Create the subplots\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(8, 8))\n",
    "\n",
    "# Plot the training and validation losses\n",
    "#ax1.set_ylim(bottom=0)\n",
    "ax1.plot(epochs, train_losses, label='train loss')\n",
    "ax1.plot(epochs, val_losses, label='val loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the training and validation accuracies\n",
    "ax2.set_ylim(bottom=0)\n",
    "ax2.plot(epochs, train_accs, label='train acc')\n",
    "ax2.plot(epochs, val_accs, label='val acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# Guardar el plot con un nombre personalizado\n",
    "#plt.savefig('lr=0,01_batch_size=64_model=EfficientNetB5_frozenLast10.pdf')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146f714-dc43-400d-ab2b-99df3d132ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "import torch\n",
    "\n",
    "# = YourModel()\n",
    "model.load_state_dict(torch.load(\"best_model_EfficientNetB2_spatialattention.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c19ca7-0a5d-4a17-bb5b-3d869308d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NormalVsAbnormalInferenceDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, labels, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28d821-94ff-43cb-883f-e574ac758f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class NormalVsAbnormalInferenceDataset(Dataset):\n",
    "    def __init__(self, images_filepaths,labels, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_cmyk = np.array(Image.fromarray(image).convert('CMYK'))\n",
    "        image_cmy = image_cmyk[..., :3]  # Seleccionar solo los canales C, M y Y\n",
    "        image_luv = cv2.cvtColor(image, cv2.COLOR_RGB2Luv)\n",
    "\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image_RGB = self.transform(image=image_RGB)[\"image\"]\n",
    "            image_luv = self.transform(image=image_luv)[\"image\"]\n",
    "            image_cmy = self.transform(image=image_cmy)[\"image\"]\n",
    "          # Convert numpy arrays to PyTorch tensors\n",
    "        image_RGB = torch.from_numpy(image_RGB.transpose(2, 0, 1))\n",
    "        image_luv = torch.from_numpy(image_luv.transpose(2, 0, 1))\n",
    "        image_cmy = torch.from_numpy(np.array(image_cmy).transpose(2, 0, 1))\n",
    "        #print(image_RGB.shape)\n",
    "        #print(image_luv.shape)\n",
    "        #print(image_cmy.shape)\n",
    "\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        # Concatenate the three representations of color\n",
    "        image = torch.cat((image_RGB, image_cmy, image_luv), dim=2)\n",
    "        #print(image.shape)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52bfc4-edf5-4583-95ad-adc6cfae08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=160),\n",
    "        A.CenterCrop(height=128, width=128),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(), #solo lo quito si en la funcion de arriba estoy ya creando el tensor\n",
    "        \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf513bc-1756-4548-b608-2613101fc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def get_test_labels(images_filepaths):\n",
    "    labels = []\n",
    "    for filepath in images_filepaths:\n",
    "        match = re.search(r\"\\d+\", filepath)\n",
    "        if match and int(match.group()) <= 143:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df4874-99ad-4a96-8979-af7c3f18fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_test_labels(images_filepaths):\n",
    "    labels = []\n",
    "    for filepath in images_filepaths:\n",
    "        if \"Normal\" in filepath:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return labels\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da8930-2aa8-4790-a499-7812126d9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_folder = '/Users/guill/Escritorio/TesisLisboa/archive/DFU/TestSet/test'\n",
    "\n",
    "test_image_filepaths = [os.path.join(test_image_folder, f) for f in os.listdir(test_image_folder) if f.endswith('.jpg') or f.endswith('.png') ]\n",
    "\n",
    "#print(test_image_filepaths)\n",
    "\n",
    "test_image_labels = get_test_labels(test_image_filepaths) # lista de etiquetas, en el mismo orden que las imágenes de prueba\n",
    "#print(test_image_labels)\n",
    "\n",
    "test_dataset = NormalVsAbnormalInferenceDataset(test_image_filepaths, test_image_labels, transform=test_transform)\n",
    "#print(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True)\n",
    "#print(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3e43d-645f-471d-84c2-24841f3a4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = model.eval()\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        labels = labels.to(params[\"device\"], non_blocking=True)\n",
    "        output = model(images)\n",
    "        predictions = torch.sigmoid(output).cpu().numpy()\n",
    "        predicted_labels += predictions.tolist()\n",
    "        true_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "predicted_labels = np.array(predicted_labels)  # Convert to numpy array\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, [1 if pred > 0.5 else 0 for pred in predicted_labels])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix EfficientNetB2')\n",
    "plt.savefig('confusion_matrix_efficientNetB2.png') \n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a33ac-87e7-4728-8f86-b2e8936e0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model = model.eval()\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_dataloader:\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        labels = labels.to(params[\"device\"], non_blocking=True)\n",
    "        output = model(images)\n",
    "        predictions = torch.sigmoid(output).cpu().numpy()\n",
    "        predicted_labels += predictions.tolist()\n",
    "        \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_image_labels, predicted_labels, drop_intermediate=False)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig('roc_curve_EfficientNetB2_spatialattention.png') # Guarda la imagen como 'roc_curve.png'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67db64-25e6-4a43-92fd-734f9e291963",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(len(test_image_labels))\n",
    "print(len(predicted_labels))\n",
    "print(test_image_labels)\n",
    "print(predicted_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3431f7-d1a7-49fb-92fd-6a11aad5d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#F1-Score Normalizado\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = model.eval()\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        labels = labels.to(params[\"device\"], non_blocking=True)\n",
    "        output = model(images)\n",
    "        predictions = torch.sigmoid(output).cpu().numpy()\n",
    "        predicted_labels += predictions.tolist()\n",
    "\n",
    "\n",
    "predicted_labels_discrete = np.where(np.array(predicted_labels) >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "# Calcular el F1-score normalizado\n",
    "f1score = f1_score(test_image_labels, predicted_labels_discrete, average='weighted')\n",
    "\n",
    "print(\"F1-score normalizado:\", f1score)\n",
    "\n",
    "\n",
    "# Verificar si existe el archivo de resultados\n",
    "if os.path.isfile('resultados_F1Score.xlsx'):\n",
    "    # Cargar el archivo existente en un DataFrame de pandas\n",
    "    results_df = pd.read_excel('resultados_F1Score.xlsx')\n",
    "else:\n",
    "    # Si no existe, crear un DataFrame vacío\n",
    "    results_df = pd.DataFrame(columns=['Modelo', 'F1-score'])\n",
    "\n",
    "# Agregar los resultados del nuevo modelo al DataFrame\n",
    "new_row = pd.DataFrame({'Modelo': ['EfficientNetB2_spatialattention'], 'F1-score': [f1score]})\n",
    "results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame en un archivo de Excel\n",
    "results_df.to_excel('resultados_F1Score.xlsx', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929eb39-f823-4882-ae29-eef2afd4db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = model.eval()\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        labels = labels.to(params[\"device\"], non_blocking=True)\n",
    "        output = model(images)\n",
    "        predictions = torch.sigmoid(output).cpu().numpy()\n",
    "        predicted_labels += predictions.tolist()\n",
    "\n",
    "predicted_labels_discrete = np.where(np.array(predicted_labels) >= 0.5, 1, 0)\n",
    "\n",
    "# Calcular el MAP\n",
    "map_score = average_precision_score(test_image_labels, predicted_labels_discrete, average='macro')\n",
    "\n",
    "print(\"MAP:\", map_score)\n",
    "\n",
    "\n",
    "import os.path\n",
    "\n",
    "# Verificar si existe el archivo de resultados\n",
    "if os.path.isfile('resultados_MAP.xlsx'):\n",
    "    # Cargar el archivo existente en un DataFrame de pandas\n",
    "    resultados = pd.read_excel('resultados_MAP.xlsx')\n",
    "else:\n",
    "    # Si no existe, crear un DataFrame vacío\n",
    "    resultados = pd.DataFrame(columns=['Modelo', 'MAP'])\n",
    "\n",
    "# Agregar los resultados del nuevo modelo al DataFrame\n",
    "new_row = pd.DataFrame({'Modelo': ['EfficientNetB2_spatialattention'], 'MAP': [map_score]})\n",
    "resultados = pd.concat([resultados, new_row], ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame en un archivo de Excel\n",
    "resultados.to_excel('resultados_MAP.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6bb3d-3785-407c-ab33-578738600aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Evaluacion del test con sus respectivos porcentajes\n",
    "import cv2\n",
    "\n",
    "model = model.eval()\n",
    "predicted_probs = []\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_dataloader:\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        output = model(images)\n",
    "        probabilities = torch.sigmoid(output).cpu().numpy()\n",
    "        predictions = (torch.sigmoid(output) >= 0.5)[:, 0]\n",
    "        predicted_labels += [\"Normal\" if is_normal else \"Abnormal\" for is_normal in predictions]\n",
    "        predicted_probs += [probs.tolist() for probs in probabilities]\n",
    "\n",
    "\n",
    "# Imprimir el nombre de la imagen y su etiqueta\n",
    "for i, filename in enumerate(os.listdir(test_image_folder)):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        if i < len(predicted_labels):\n",
    "            label = predicted_labels[i]\n",
    "            prob_normal = predicted_probs[i][0]\n",
    "            prob_abnormal = 1 - prob_normal\n",
    "        \n",
    "            print(f\"{filename}: {label} - Probabilidades: Normal: {prob_normal:.2f}, Abnormal: {prob_abnormal:.2f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c35d2-b8c7-4658-9941-e8de6e5ab0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9781d-9a5f-42ba-8c45-042917eb2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
